{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30524830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:11.179519Z",
     "iopub.status.busy": "2022-10-03T23:12:11.179078Z",
     "iopub.status.idle": "2022-10-03T23:12:20.277577Z",
     "shell.execute_reply": "2022-10-03T23:12:20.276478Z"
    },
    "papermill": {
     "duration": 9.108465,
     "end_time": "2022-10-03T23:12:20.279897",
     "exception": false,
     "start_time": "2022-10-03T23:12:11.171432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPool1D \n",
    "from keras.layers import BatchNormalization, concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import CategoricalCrossentropy, MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4bc084b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.289630Z",
     "iopub.status.busy": "2022-10-03T23:12:20.288866Z",
     "iopub.status.idle": "2022-10-03T23:12:20.293963Z",
     "shell.execute_reply": "2022-10-03T23:12:20.292454Z"
    },
    "papermill": {
     "duration": 0.012644,
     "end_time": "2022-10-03T23:12:20.296517",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.283873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT/'input'\n",
    "DATA = INPUT/'feedback-prize-english-language-learning'\n",
    "WORK = ROOT/'working'\n",
    "VECS = INPUT/'vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50de5a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.305149Z",
     "iopub.status.busy": "2022-10-03T23:12:20.304813Z",
     "iopub.status.idle": "2022-10-03T23:12:20.310266Z",
     "shell.execute_reply": "2022-10-03T23:12:20.308970Z"
    },
    "papermill": {
     "duration": 0.012937,
     "end_time": "2022-10-03T23:12:20.313104",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.300167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_col = ['cohesion', 'syntax', 'vocabulary',\n",
    "              'phraseology', 'grammar', 'conventions']\n",
    "max_len = 1440 #200\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "max_words =30000\n",
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673110c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.322363Z",
     "iopub.status.busy": "2022-10-03T23:12:20.321955Z",
     "iopub.status.idle": "2022-10-03T23:12:20.331143Z",
     "shell.execute_reply": "2022-10-03T23:12:20.329469Z"
    },
    "papermill": {
     "duration": 0.016747,
     "end_time": "2022-10-03T23:12:20.333689",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.316942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decontractions(phrase):\n",
    "    phrase = re.sub(r\"wan\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \"not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(text.values):\n",
    "        sentence = str(sentence)\n",
    "        sent = sentence.replace('\\n\\n', ' ')\n",
    "        sent = decontractions(sent)\n",
    "        preprocessed.append(sent.lower().strip())\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6098d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.343622Z",
     "iopub.status.busy": "2022-10-03T23:12:20.342370Z",
     "iopub.status.idle": "2022-10-03T23:12:20.350990Z",
     "shell.execute_reply": "2022-10-03T23:12:20.350345Z"
    },
    "papermill": {
     "duration": 0.015546,
     "end_time": "2022-10-03T23:12:20.353048",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.337502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_init(max_len, max_words, embedding_matrix):\n",
    "    input_1 = Input(shape=(max_len,))\n",
    "    embed = Embedding(input_dim=max_words,\n",
    "                      output_dim=128,\n",
    "                      input_length=max_len,\n",
    "                      weights=[embedding_matrix],\n",
    "                      trainable=False)(input_1)\n",
    "\n",
    "    branches = []\n",
    "    x = Dropout(0.2)(embed)\n",
    "    for i in range(2, 6):\n",
    "        branch = Conv1D(128, i,\n",
    "                        padding = 'valid',\n",
    "                        activation = 'relu')(x)\n",
    "        branch = GlobalMaxPool1D()(branch)\n",
    "        branches.append(branch)\n",
    "\n",
    "    x = concatenate(branches, axis=1)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(9)(x)\n",
    "    output = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs = [input_1],\n",
    "                  outputs = [output])\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0f253b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.361925Z",
     "iopub.status.busy": "2022-10-03T23:12:20.361478Z",
     "iopub.status.idle": "2022-10-03T23:12:20.638428Z",
     "shell.execute_reply": "2022-10-03T23:12:20.637020Z"
    },
    "papermill": {
     "duration": 0.284095,
     "end_time": "2022-10-03T23:12:20.640735",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.356640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA/'train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c27f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:20.650032Z",
     "iopub.status.busy": "2022-10-03T23:12:20.649641Z",
     "iopub.status.idle": "2022-10-03T23:12:22.677114Z",
     "shell.execute_reply": "2022-10-03T23:12:22.676067Z"
    },
    "papermill": {
     "duration": 2.034651,
     "end_time": "2022-10-03T23:12:22.679225",
     "exception": false,
     "start_time": "2022-10-03T23:12:20.644574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3911/3911 [00:00<00:00, 37286.13it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train.full_text = preprocess(df_train.full_text)\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df_train.full_text)\n",
    "df_train['token'] = token.texts_to_sequences(df_train.full_text)\n",
    "x_train = pad_sequences(df_train.token, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7faddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:22.690112Z",
     "iopub.status.busy": "2022-10-03T23:12:22.689796Z",
     "iopub.status.idle": "2022-10-03T23:12:22.694720Z",
     "shell.execute_reply": "2022-10-03T23:12:22.693017Z"
    },
    "papermill": {
     "duration": 0.013597,
     "end_time": "2022-10-03T23:12:22.697328",
     "exception": false,
     "start_time": "2022-10-03T23:12:22.683731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lines = list(token.word_index.keys())\n",
    "#with open(WORK/'token.txt', 'w') as file:\n",
    "#    for line in lines:\n",
    "#        file.write(line + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca66773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:22.707532Z",
     "iopub.status.busy": "2022-10-03T23:12:22.707182Z",
     "iopub.status.idle": "2022-10-03T23:12:22.967915Z",
     "shell.execute_reply": "2022-10-03T23:12:22.966861Z"
    },
    "papermill": {
     "duration": 0.268391,
     "end_time": "2022-10-03T23:12:22.970191",
     "exception": false,
     "start_time": "2022-10-03T23:12:22.701800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(VECS/'embedding.npy')\n",
    "vocab_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeda4977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T23:12:22.981165Z",
     "iopub.status.busy": "2022-10-03T23:12:22.980532Z",
     "iopub.status.idle": "2022-10-04T01:50:36.510176Z",
     "shell.execute_reply": "2022-10-04T01:50:36.508981Z"
    },
    "papermill": {
     "duration": 9493.537214,
     "end_time": "2022-10-04T01:50:36.511960",
     "exception": false,
     "start_time": "2022-10-03T23:12:22.974746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]2022-10-03 23:12:23.051169: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-10-03 23:12:23.369531: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 73s 655ms/step - loss: 1.8662 - accuracy: 0.2623 - val_loss: 1.7319 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26020, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 71s 641ms/step - loss: 1.7294 - accuracy: 0.2720 - val_loss: 1.6769 - val_accuracy: 0.2730\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.26020 to 0.27296, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 70s 639ms/step - loss: 1.7190 - accuracy: 0.2742 - val_loss: 1.6990 - val_accuracy: 0.2832\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.27296 to 0.28316, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 71s 644ms/step - loss: 1.7004 - accuracy: 0.2808 - val_loss: 1.6682 - val_accuracy: 0.2781\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.28316\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 72s 657ms/step - loss: 1.6963 - accuracy: 0.2725 - val_loss: 1.6682 - val_accuracy: 0.2755\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.28316\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 73s 667ms/step - loss: 1.6818 - accuracy: 0.2853 - val_loss: 1.6759 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.28316 to 0.30612, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 72s 654ms/step - loss: 1.6696 - accuracy: 0.2930 - val_loss: 1.6558 - val_accuracy: 0.2883\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.30612\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 70s 638ms/step - loss: 1.6615 - accuracy: 0.2904 - val_loss: 1.7002 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.30612\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 71s 650ms/step - loss: 1.6495 - accuracy: 0.2904 - val_loss: 1.6335 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.30612 to 0.31633, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 73s 660ms/step - loss: 1.6359 - accuracy: 0.2927 - val_loss: 1.6272 - val_accuracy: 0.3036\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.31633\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 91s 923ms/step - loss: 1.6281 - accuracy: 0.3069 - val_loss: 1.6226 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.31633\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 85s 870ms/step - loss: 1.6231 - accuracy: 0.3098 - val_loss: 1.6054 - val_accuracy: 0.3091\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.31633\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 85s 864ms/step - loss: 1.5970 - accuracy: 0.3235 - val_loss: 1.6003 - val_accuracy: 0.3269\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.31633 to 0.32695, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 86s 881ms/step - loss: 1.5844 - accuracy: 0.3267 - val_loss: 1.6177 - val_accuracy: 0.3244\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.32695\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 86s 878ms/step - loss: 1.5681 - accuracy: 0.3254 - val_loss: 1.5932 - val_accuracy: 0.3231\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.32695\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 85s 868ms/step - loss: 1.5534 - accuracy: 0.3325 - val_loss: 1.6026 - val_accuracy: 0.3065\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.32695\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 85s 868ms/step - loss: 1.5361 - accuracy: 0.3434 - val_loss: 1.5687 - val_accuracy: 0.3487\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.32695 to 0.34866, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 84s 863ms/step - loss: 1.5079 - accuracy: 0.3558 - val_loss: 1.5455 - val_accuracy: 0.3218\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.34866\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 86s 881ms/step - loss: 1.4755 - accuracy: 0.3651 - val_loss: 1.5374 - val_accuracy: 0.3206\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.34866\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 86s 877ms/step - loss: 1.4642 - accuracy: 0.3641 - val_loss: 1.5520 - val_accuracy: 0.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [26:17<2:11:29, 1577.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.34866\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 72s 642ms/step - loss: 1.8571 - accuracy: 0.2904 - val_loss: 1.6610 - val_accuracy: 0.3240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32398, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 71s 649ms/step - loss: 1.7159 - accuracy: 0.2876 - val_loss: 1.6557 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.32398\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 69s 630ms/step - loss: 1.7003 - accuracy: 0.2981 - val_loss: 1.6985 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.32398\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 69s 626ms/step - loss: 1.6865 - accuracy: 0.2981 - val_loss: 1.6375 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.32398\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 70s 640ms/step - loss: 1.6791 - accuracy: 0.2884 - val_loss: 1.6684 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.32398\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 73s 659ms/step - loss: 1.6634 - accuracy: 0.3132 - val_loss: 1.6614 - val_accuracy: 0.3393\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.32398 to 0.33929, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 71s 646ms/step - loss: 1.6599 - accuracy: 0.3245 - val_loss: 1.6834 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.33929\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 72s 656ms/step - loss: 1.6511 - accuracy: 0.3188 - val_loss: 1.6317 - val_accuracy: 0.3393\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.33929\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 72s 655ms/step - loss: 1.6480 - accuracy: 0.3186 - val_loss: 1.6183 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.33929\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 71s 648ms/step - loss: 1.6245 - accuracy: 0.3174 - val_loss: 1.6051 - val_accuracy: 0.3546\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.33929 to 0.35459, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 88s 892ms/step - loss: 1.6183 - accuracy: 0.3264 - val_loss: 1.6099 - val_accuracy: 0.3167\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.35459\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 86s 873ms/step - loss: 1.5960 - accuracy: 0.3258 - val_loss: 1.5970 - val_accuracy: 0.3346\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.35459\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 86s 873ms/step - loss: 1.5645 - accuracy: 0.3357 - val_loss: 1.5749 - val_accuracy: 0.3308\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.35459\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 85s 870ms/step - loss: 1.5381 - accuracy: 0.3507 - val_loss: 1.5392 - val_accuracy: 0.3423\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.35459\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 87s 884ms/step - loss: 1.5162 - accuracy: 0.3584 - val_loss: 1.5596 - val_accuracy: 0.3602\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.35459 to 0.36015, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 86s 882ms/step - loss: 1.4974 - accuracy: 0.3721 - val_loss: 1.5708 - val_accuracy: 0.3538\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.36015\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 96s 980ms/step - loss: 1.4728 - accuracy: 0.3715 - val_loss: 1.5211 - val_accuracy: 0.3755\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.36015 to 0.37548, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 87s 889ms/step - loss: 1.4660 - accuracy: 0.3855 - val_loss: 1.5371 - val_accuracy: 0.3448\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.37548\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 84s 857ms/step - loss: 1.4341 - accuracy: 0.3846 - val_loss: 1.5250 - val_accuracy: 0.3716\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.37548\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 84s 855ms/step - loss: 1.4285 - accuracy: 0.3971 - val_loss: 1.5615 - val_accuracy: 0.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [52:37<1:45:14, 1578.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.37548\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 72s 647ms/step - loss: 1.7009 - accuracy: 0.3564 - val_loss: 1.5705 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.39286, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 70s 640ms/step - loss: 1.5900 - accuracy: 0.3583 - val_loss: 1.5518 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.39286\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 73s 665ms/step - loss: 1.5689 - accuracy: 0.3831 - val_loss: 1.5527 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.39286\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 75s 685ms/step - loss: 1.5681 - accuracy: 0.3805 - val_loss: 1.5464 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.39286\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 74s 668ms/step - loss: 1.5711 - accuracy: 0.3797 - val_loss: 1.5439 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.39286\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 72s 657ms/step - loss: 1.5649 - accuracy: 0.3819 - val_loss: 1.5433 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.39286\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 73s 663ms/step - loss: 1.5634 - accuracy: 0.3831 - val_loss: 1.5416 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.39286\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 71s 646ms/step - loss: 1.5638 - accuracy: 0.3802 - val_loss: 1.5476 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.39286\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 72s 655ms/step - loss: 1.5594 - accuracy: 0.3782 - val_loss: 1.5627 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.39286\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 72s 657ms/step - loss: 1.5633 - accuracy: 0.3819 - val_loss: 1.5420 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.39286\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 87s 883ms/step - loss: 1.5940 - accuracy: 0.3622 - val_loss: 1.5610 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.39286 to 0.39847, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 86s 882ms/step - loss: 1.5770 - accuracy: 0.3593 - val_loss: 1.6053 - val_accuracy: 0.3908\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.39847\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 88s 898ms/step - loss: 1.5706 - accuracy: 0.3728 - val_loss: 1.5515 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.39847\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 86s 875ms/step - loss: 1.5705 - accuracy: 0.3750 - val_loss: 1.5533 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.39847\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 86s 876ms/step - loss: 1.5617 - accuracy: 0.3766 - val_loss: 1.5567 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.39847\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 87s 884ms/step - loss: 1.5606 - accuracy: 0.3788 - val_loss: 1.5876 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.39847\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 87s 887ms/step - loss: 1.5594 - accuracy: 0.3776 - val_loss: 1.5420 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.39847\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 85s 865ms/step - loss: 1.5583 - accuracy: 0.3740 - val_loss: 1.5590 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.39847\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 84s 860ms/step - loss: 1.5522 - accuracy: 0.3808 - val_loss: 1.5515 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.39847\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 86s 876ms/step - loss: 1.5466 - accuracy: 0.3808 - val_loss: 1.5458 - val_accuracy: 0.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [1:19:04<1:19:08, 1582.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.39847\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 72s 644ms/step - loss: 1.8818 - accuracy: 0.2492 - val_loss: 1.7688 - val_accuracy: 0.2168\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21684, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 71s 643ms/step - loss: 1.7345 - accuracy: 0.2515 - val_loss: 1.7120 - val_accuracy: 0.2168\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.21684\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 70s 635ms/step - loss: 1.7169 - accuracy: 0.2756 - val_loss: 1.7012 - val_accuracy: 0.2934\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.21684 to 0.29337, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 71s 649ms/step - loss: 1.7051 - accuracy: 0.2813 - val_loss: 1.7249 - val_accuracy: 0.2423\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.29337\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 73s 660ms/step - loss: 1.6835 - accuracy: 0.2819 - val_loss: 1.6920 - val_accuracy: 0.2883\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.29337\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 72s 654ms/step - loss: 1.6728 - accuracy: 0.3015 - val_loss: 1.6725 - val_accuracy: 0.3036\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.29337 to 0.30357, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 72s 655ms/step - loss: 1.6592 - accuracy: 0.2953 - val_loss: 1.6612 - val_accuracy: 0.3495\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.30357 to 0.34949, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 71s 643ms/step - loss: 1.6328 - accuracy: 0.3069 - val_loss: 1.6749 - val_accuracy: 0.2704\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.34949\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 71s 644ms/step - loss: 1.6292 - accuracy: 0.3063 - val_loss: 1.6500 - val_accuracy: 0.2934\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.34949\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 70s 634ms/step - loss: 1.6151 - accuracy: 0.3134 - val_loss: 1.6442 - val_accuracy: 0.3520\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.34949 to 0.35204, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 84s 854ms/step - loss: 1.5981 - accuracy: 0.3207 - val_loss: 1.6210 - val_accuracy: 0.3052\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.35204\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 83s 844ms/step - loss: 1.6065 - accuracy: 0.3095 - val_loss: 1.5876 - val_accuracy: 0.2937\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.35204\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 84s 860ms/step - loss: 1.5546 - accuracy: 0.3370 - val_loss: 1.6008 - val_accuracy: 0.3027\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.35204\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 85s 871ms/step - loss: 1.5423 - accuracy: 0.3424 - val_loss: 1.5386 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.35204\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 85s 870ms/step - loss: 1.5115 - accuracy: 0.3718 - val_loss: 1.5668 - val_accuracy: 0.3231\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.35204\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 85s 867ms/step - loss: 1.5037 - accuracy: 0.3581 - val_loss: 1.5512 - val_accuracy: 0.3103\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.35204\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 86s 875ms/step - loss: 1.4817 - accuracy: 0.3744 - val_loss: 1.5562 - val_accuracy: 0.3180\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.35204\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 85s 869ms/step - loss: 1.4672 - accuracy: 0.3817 - val_loss: 1.5833 - val_accuracy: 0.3052\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.35204\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 86s 876ms/step - loss: 1.4305 - accuracy: 0.3926 - val_loss: 1.5289 - val_accuracy: 0.3129\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.35204\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 85s 873ms/step - loss: 1.4376 - accuracy: 0.4015 - val_loss: 1.5447 - val_accuracy: 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [1:45:36<52:52, 1586.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.35204\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 73s 660ms/step - loss: 1.8917 - accuracy: 0.2307 - val_loss: 1.7532 - val_accuracy: 0.2474\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.24745, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 75s 683ms/step - loss: 1.7929 - accuracy: 0.2296 - val_loss: 1.7219 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.24745 to 0.25510, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 73s 665ms/step - loss: 1.7576 - accuracy: 0.2509 - val_loss: 1.7102 - val_accuracy: 0.2270\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.25510\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 72s 654ms/step - loss: 1.7426 - accuracy: 0.2563 - val_loss: 1.6779 - val_accuracy: 0.2628\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.25510 to 0.26276, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 74s 676ms/step - loss: 1.7279 - accuracy: 0.2577 - val_loss: 1.7106 - val_accuracy: 0.2296\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.26276\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 73s 664ms/step - loss: 1.7243 - accuracy: 0.2722 - val_loss: 1.6839 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.26276 to 0.28571, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 72s 656ms/step - loss: 1.6966 - accuracy: 0.2720 - val_loss: 1.6869 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.28571 to 0.30612, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 73s 664ms/step - loss: 1.6787 - accuracy: 0.2825 - val_loss: 1.6452 - val_accuracy: 0.2704\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.30612\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 72s 659ms/step - loss: 1.6609 - accuracy: 0.2992 - val_loss: 1.6591 - val_accuracy: 0.2577\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.30612\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 74s 674ms/step - loss: 1.6635 - accuracy: 0.2864 - val_loss: 1.6374 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.30612\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 88s 894ms/step - loss: 1.6824 - accuracy: 0.2698 - val_loss: 1.7254 - val_accuracy: 0.2631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.30612\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 86s 880ms/step - loss: 1.6713 - accuracy: 0.2868 - val_loss: 1.6561 - val_accuracy: 0.2771\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.30612\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 87s 883ms/step - loss: 1.6406 - accuracy: 0.2983 - val_loss: 1.7591 - val_accuracy: 0.2644\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.30612\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 87s 889ms/step - loss: 1.6140 - accuracy: 0.3219 - val_loss: 1.6152 - val_accuracy: 0.2835\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.30612\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 84s 861ms/step - loss: 1.5973 - accuracy: 0.3328 - val_loss: 1.6475 - val_accuracy: 0.2912\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.30612\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 85s 868ms/step - loss: 1.5692 - accuracy: 0.3226 - val_loss: 1.6115 - val_accuracy: 0.3167\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.30612 to 0.31673, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 85s 864ms/step - loss: 1.5511 - accuracy: 0.3472 - val_loss: 1.6495 - val_accuracy: 0.2874\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.31673\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 84s 853ms/step - loss: 1.5272 - accuracy: 0.3513 - val_loss: 1.6421 - val_accuracy: 0.2950\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.31673\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 85s 865ms/step - loss: 1.5006 - accuracy: 0.3622 - val_loss: 1.6213 - val_accuracy: 0.3001\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.31673\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 86s 876ms/step - loss: 1.4839 - accuracy: 0.3645 - val_loss: 1.5782 - val_accuracy: 0.3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [2:12:05<26:27, 1587.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy improved from 0.31673 to 0.31801, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 74s 667ms/step - loss: 1.8966 - accuracy: 0.2666 - val_loss: 1.7695 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.29592, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 71s 650ms/step - loss: 1.7614 - accuracy: 0.2759 - val_loss: 1.7020 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.29592\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 73s 661ms/step - loss: 1.7381 - accuracy: 0.2850 - val_loss: 1.7296 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.29592\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 71s 642ms/step - loss: 1.7316 - accuracy: 0.2856 - val_loss: 1.6990 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.29592\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 73s 662ms/step - loss: 1.7121 - accuracy: 0.2941 - val_loss: 1.7424 - val_accuracy: 0.2577\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.29592\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 72s 659ms/step - loss: 1.7155 - accuracy: 0.2737 - val_loss: 1.7167 - val_accuracy: 0.2526\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.29592\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 72s 653ms/step - loss: 1.7142 - accuracy: 0.2944 - val_loss: 1.6955 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.29592\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 73s 660ms/step - loss: 1.7087 - accuracy: 0.2910 - val_loss: 1.6826 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.29592\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 72s 656ms/step - loss: 1.7041 - accuracy: 0.2901 - val_loss: 1.6689 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.29592\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 73s 664ms/step - loss: 1.7057 - accuracy: 0.2961 - val_loss: 1.6862 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.29592\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 87s 879ms/step - loss: 1.7701 - accuracy: 0.2785 - val_loss: 1.7221 - val_accuracy: 0.2976\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.29592 to 0.29757, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 84s 860ms/step - loss: 1.7595 - accuracy: 0.2753 - val_loss: 1.7280 - val_accuracy: 0.2312\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.29757\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 84s 856ms/step - loss: 1.7156 - accuracy: 0.2938 - val_loss: 1.7033 - val_accuracy: 0.2503\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.29757\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 84s 856ms/step - loss: 1.7166 - accuracy: 0.2807 - val_loss: 1.7062 - val_accuracy: 0.2324\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.29757\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 84s 857ms/step - loss: 1.7108 - accuracy: 0.2912 - val_loss: 1.6898 - val_accuracy: 0.2963\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.29757\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 83s 850ms/step - loss: 1.7045 - accuracy: 0.2864 - val_loss: 1.7010 - val_accuracy: 0.2912\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.29757\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 84s 854ms/step - loss: 1.7032 - accuracy: 0.2944 - val_loss: 1.7083 - val_accuracy: 0.3116\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.29757 to 0.31162, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 84s 855ms/step - loss: 1.7030 - accuracy: 0.2877 - val_loss: 1.6795 - val_accuracy: 0.3091\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.31162\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 84s 856ms/step - loss: 1.6873 - accuracy: 0.2957 - val_loss: 1.6714 - val_accuracy: 0.3027\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.31162\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 86s 881ms/step - loss: 1.6802 - accuracy: 0.3098 - val_loss: 1.6842 - val_accuracy: 0.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [2:38:13<00:00, 1582.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.31162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(target_col):\n",
    "    y_train = to_categorical(df_train[col]*2-2, num_classes)\n",
    "    model_save = WORK/f'model_{col}.h5'\n",
    "    checkpoint = ModelCheckpoint(model_save,\n",
    "                                 monitor = 'val_accuracy',\n",
    "                                 save_best_only = True,\n",
    "                                 verbose = 1)\n",
    "    model = model_init(max_len, vocab_size, embedding_matrix)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        validation_split = 0.1,\n",
    "                        callbacks = [checkpoint],\n",
    "                        verbose = 1)\n",
    "    model.load_weights(model_save)\n",
    "    model.layers[1].trainable = True\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    history_2 = model.fit(x_train, y_train,\n",
    "                          batch_size = batch_size,\n",
    "                          epochs = epochs,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [checkpoint],\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d28d46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T01:50:37.954022Z",
     "iopub.status.busy": "2022-10-04T01:50:37.953581Z",
     "iopub.status.idle": "2022-10-04T01:50:37.984749Z",
     "shell.execute_reply": "2022-10-04T01:50:37.983689Z"
    },
    "papermill": {
     "duration": 0.753913,
     "end_time": "2022-10-04T01:50:37.986645",
     "exception": false,
     "start_time": "2022-10-04T01:50:37.232732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(DATA/'test.csv')\n",
    "sample = pd.read_csv(DATA/'sample_submission.csv')\n",
    "sample.text_id = test.text_id\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a50cbd88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T01:50:39.474186Z",
     "iopub.status.busy": "2022-10-04T01:50:39.473571Z",
     "iopub.status.idle": "2022-10-04T01:50:39.483707Z",
     "shell.execute_reply": "2022-10-04T01:50:39.482067Z"
    },
    "papermill": {
     "duration": 0.709483,
     "end_time": "2022-10-04T01:50:39.486438",
     "exception": false,
     "start_time": "2022-10-04T01:50:38.776955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11554.56it/s]\n"
     ]
    }
   ],
   "source": [
    "test.full_text = preprocess(test.full_text)\n",
    "x_test = token.texts_to_sequences(test.full_text)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f72a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T01:50:40.997483Z",
     "iopub.status.busy": "2022-10-04T01:50:40.996831Z",
     "iopub.status.idle": "2022-10-04T01:50:41.693997Z",
     "shell.execute_reply": "2022-10-04T01:50:41.692165Z"
    },
    "papermill": {
     "duration": 1.409774,
     "end_time": "2022-10-04T01:50:41.696477",
     "exception": false,
     "start_time": "2022-10-04T01:50:40.286703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:01,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:00<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:00<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.78it/s]\n"
     ]
    }
   ],
   "source": [
    "def label_transform(pred):\n",
    "    labels = []\n",
    "    for i in range(len(pred)):\n",
    "        max_p = max(pred[i])\n",
    "        for j in range(num_classes):\n",
    "            if max_p == pred[i][j]:\n",
    "                ind = (j + 2) / 2\n",
    "                break\n",
    "        labels.append(ind)\n",
    "    return labels\n",
    "\n",
    "for col in tqdm(target_col):\n",
    "    model.load_weights(model_save)\n",
    "    test_pred = model.predict(x_test,\n",
    "                              batch_size = batch_size,\n",
    "                              verbose = 1)\n",
    "    sample[col] = label_transform(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "609bec82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T01:50:43.207835Z",
     "iopub.status.busy": "2022-10-04T01:50:43.207472Z",
     "iopub.status.idle": "2022-10-04T01:50:43.215734Z",
     "shell.execute_reply": "2022-10-04T01:50:43.214585Z"
    },
    "papermill": {
     "duration": 0.8214,
     "end_time": "2022-10-04T01:50:43.217970",
     "exception": false,
     "start_time": "2022-10-04T01:50:42.396570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9524.692273,
   "end_time": "2022-10-04T01:50:46.801416",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-03T23:12:02.109143",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
