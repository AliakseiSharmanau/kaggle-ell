{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e3594a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:27.533834Z",
     "iopub.status.busy": "2022-10-02T21:42:27.533514Z",
     "iopub.status.idle": "2022-10-02T21:42:33.161577Z",
     "shell.execute_reply": "2022-10-02T21:42:33.160602Z"
    },
    "papermill": {
     "duration": 5.635767,
     "end_time": "2022-10-02T21:42:33.164028",
     "exception": false,
     "start_time": "2022-10-02T21:42:27.528261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPool1D \n",
    "from keras.layers import BatchNormalization, concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import CategoricalCrossentropy, MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a1a239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.171902Z",
     "iopub.status.busy": "2022-10-02T21:42:33.171349Z",
     "iopub.status.idle": "2022-10-02T21:42:33.177045Z",
     "shell.execute_reply": "2022-10-02T21:42:33.176028Z"
    },
    "papermill": {
     "duration": 0.011839,
     "end_time": "2022-10-02T21:42:33.179178",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.167339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT/'input'\n",
    "DATA = INPUT/'feedback-prize-english-language-learning'\n",
    "WORK = ROOT/'working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea89000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.186852Z",
     "iopub.status.busy": "2022-10-02T21:42:33.186541Z",
     "iopub.status.idle": "2022-10-02T21:42:33.191455Z",
     "shell.execute_reply": "2022-10-02T21:42:33.190499Z"
    },
    "papermill": {
     "duration": 0.010662,
     "end_time": "2022-10-02T21:42:33.193121",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.182459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_col = ['cohesion', 'syntax', 'vocabulary',\n",
    "              'phraseology', 'grammar', 'conventions']\n",
    "max_len = 1440 #200\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "max_words =30000\n",
    "num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d69791f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.200816Z",
     "iopub.status.busy": "2022-10-02T21:42:33.200514Z",
     "iopub.status.idle": "2022-10-02T21:42:33.208108Z",
     "shell.execute_reply": "2022-10-02T21:42:33.207089Z"
    },
    "papermill": {
     "duration": 0.013721,
     "end_time": "2022-10-02T21:42:33.210035",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.196314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decontractions(phrase):\n",
    "    phrase = re.sub(r\"wan\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \"not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(text.values):\n",
    "        sentence = str(sentence)\n",
    "        sent = sentence.replace('\\n\\n', ' ')\n",
    "        sent = decontractions(sent)\n",
    "        preprocessed.append(sent.lower().strip())\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bb586a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.217591Z",
     "iopub.status.busy": "2022-10-02T21:42:33.217295Z",
     "iopub.status.idle": "2022-10-02T21:42:33.224764Z",
     "shell.execute_reply": "2022-10-02T21:42:33.223941Z"
    },
    "papermill": {
     "duration": 0.013377,
     "end_time": "2022-10-02T21:42:33.226492",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.213115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_init(max_len, max_words):\n",
    "    input_1 = Input(shape=(max_len,))\n",
    "    embed = Embedding(input_dim=max_words,\n",
    "                      output_dim=128,\n",
    "                      input_length=max_len)(input_1)\n",
    "                 # weights=[embedding_matrix],\n",
    "                #  trainable=False)(input_1)\n",
    "\n",
    "    branches = []\n",
    "    x = Dropout(0.2)(embed)\n",
    "    for i in range(2, 6):\n",
    "        branch = Conv1D(128, i,\n",
    "                        padding = 'valid',\n",
    "                        activation = 'relu')(x)\n",
    "        branch = GlobalMaxPool1D()(branch)\n",
    "        branches.append(branch)\n",
    "\n",
    "    x = concatenate(branches, axis=1)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(9)(x)\n",
    "    output = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs = [input_1],\n",
    "                  outputs = [output])\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504b5776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.233804Z",
     "iopub.status.busy": "2022-10-02T21:42:33.233528Z",
     "iopub.status.idle": "2022-10-02T21:42:33.486853Z",
     "shell.execute_reply": "2022-10-02T21:42:33.486281Z"
    },
    "papermill": {
     "duration": 0.259023,
     "end_time": "2022-10-02T21:42:33.488583",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.229560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA/'train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97b3955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:33.497187Z",
     "iopub.status.busy": "2022-10-02T21:42:33.496188Z",
     "iopub.status.idle": "2022-10-02T21:42:35.210056Z",
     "shell.execute_reply": "2022-10-02T21:42:35.208891Z"
    },
    "papermill": {
     "duration": 1.720274,
     "end_time": "2022-10-02T21:42:35.212232",
     "exception": false,
     "start_time": "2022-10-02T21:42:33.491958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3911/3911 [00:00<00:00, 39135.60it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train.full_text = preprocess(df_train.full_text)\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df_train.full_text)\n",
    "df_train['token'] = token.texts_to_sequences(df_train.full_text)\n",
    "x_train = pad_sequences(df_train.token, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2648b79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T21:42:35.220512Z",
     "iopub.status.busy": "2022-10-02T21:42:35.220053Z",
     "iopub.status.idle": "2022-10-03T00:29:53.335058Z",
     "shell.execute_reply": "2022-10-03T00:29:53.334471Z"
    },
    "papermill": {
     "duration": 10038.121531,
     "end_time": "2022-10-03T00:29:53.337231",
     "exception": false,
     "start_time": "2022-10-02T21:42:35.215700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]2022-10-02 21:42:35.274713: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-10-02 21:42:35.490028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 84s 758ms/step - loss: 1.7324 - accuracy: 0.2654 - val_loss: 1.6733 - val_accuracy: 0.2755\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.27551, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 83s 756ms/step - loss: 1.6649 - accuracy: 0.3041 - val_loss: 1.6376 - val_accuracy: 0.3240\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.27551 to 0.32398, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 82s 747ms/step - loss: 1.5916 - accuracy: 0.3572 - val_loss: 1.6387 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.32398\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 83s 755ms/step - loss: 1.4945 - accuracy: 0.4135 - val_loss: 1.5698 - val_accuracy: 0.3393\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.32398 to 0.33929, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 84s 767ms/step - loss: 1.3286 - accuracy: 0.5118 - val_loss: 1.5892 - val_accuracy: 0.2781\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.33929\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 87s 793ms/step - loss: 1.1213 - accuracy: 0.6124 - val_loss: 1.6425 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.33929\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 89s 809ms/step - loss: 0.8459 - accuracy: 0.7391 - val_loss: 1.6836 - val_accuracy: 0.3061\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.33929\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 86s 782ms/step - loss: 0.5807 - accuracy: 0.8497 - val_loss: 1.8114 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.33929\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 82s 749ms/step - loss: 0.3582 - accuracy: 0.9179 - val_loss: 2.0035 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.33929\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 82s 749ms/step - loss: 0.2157 - accuracy: 0.9605 - val_loss: 2.1617 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.33929\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 77s 779ms/step - loss: 1.3481 - accuracy: 0.4974 - val_loss: 1.4197 - val_accuracy: 0.4330\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.33929 to 0.43295, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 75s 770ms/step - loss: 1.1798 - accuracy: 0.5889 - val_loss: 1.4339 - val_accuracy: 0.4100\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.43295\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 75s 765ms/step - loss: 0.9925 - accuracy: 0.6841 - val_loss: 1.4174 - val_accuracy: 0.4291\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.43295\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 75s 770ms/step - loss: 0.7815 - accuracy: 0.7695 - val_loss: 1.4423 - val_accuracy: 0.4253\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.43295\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 76s 773ms/step - loss: 0.5690 - accuracy: 0.8539 - val_loss: 1.4892 - val_accuracy: 0.4406\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.43295 to 0.44061, saving model to /kaggle/working/model_cohesion.h5\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 76s 777ms/step - loss: 0.3879 - accuracy: 0.9156 - val_loss: 1.5500 - val_accuracy: 0.4278\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.44061\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 76s 781ms/step - loss: 0.2505 - accuracy: 0.9504 - val_loss: 1.5961 - val_accuracy: 0.4125\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.44061\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 77s 784ms/step - loss: 0.1673 - accuracy: 0.9706 - val_loss: 1.6990 - val_accuracy: 0.4151\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.44061\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 79s 809ms/step - loss: 0.1072 - accuracy: 0.9827 - val_loss: 1.7627 - val_accuracy: 0.4087\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.44061\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 82s 841ms/step - loss: 0.0744 - accuracy: 0.9895 - val_loss: 1.8517 - val_accuracy: 0.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [26:54<2:14:32, 1614.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.44061\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 88s 792ms/step - loss: 1.7061 - accuracy: 0.3055 - val_loss: 1.6462 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32143, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 88s 799ms/step - loss: 1.6366 - accuracy: 0.3169 - val_loss: 1.5906 - val_accuracy: 0.3444\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.32143 to 0.34439, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 86s 782ms/step - loss: 1.5631 - accuracy: 0.3643 - val_loss: 1.5445 - val_accuracy: 0.3495\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.34439 to 0.34949, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 88s 804ms/step - loss: 1.4593 - accuracy: 0.4260 - val_loss: 1.5003 - val_accuracy: 0.3673\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.34949 to 0.36735, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 88s 800ms/step - loss: 1.3083 - accuracy: 0.5013 - val_loss: 1.4628 - val_accuracy: 0.3801\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.36735 to 0.38010, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 87s 787ms/step - loss: 1.1146 - accuracy: 0.6158 - val_loss: 1.4939 - val_accuracy: 0.3622\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.38010\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 86s 785ms/step - loss: 0.8598 - accuracy: 0.7295 - val_loss: 1.5304 - val_accuracy: 0.3648\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.38010\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 85s 774ms/step - loss: 0.6046 - accuracy: 0.8289 - val_loss: 1.6512 - val_accuracy: 0.3495\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.38010\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 89s 807ms/step - loss: 0.3904 - accuracy: 0.9074 - val_loss: 1.7811 - val_accuracy: 0.3418\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.38010\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 91s 828ms/step - loss: 0.2651 - accuracy: 0.9366 - val_loss: 1.9527 - val_accuracy: 0.3520\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.38010\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 1.0949 - accuracy: 0.6359 - val_loss: 1.2708 - val_accuracy: 0.5441\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.38010 to 0.54406, saving model to /kaggle/working/model_syntax.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 80s 813ms/step - loss: 0.9032 - accuracy: 0.7308 - val_loss: 1.2597 - val_accuracy: 0.5249\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54406\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 80s 814ms/step - loss: 0.7077 - accuracy: 0.8005 - val_loss: 1.2679 - val_accuracy: 0.5313\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.54406\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 79s 806ms/step - loss: 0.5296 - accuracy: 0.8565 - val_loss: 1.2820 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.54406\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 79s 806ms/step - loss: 0.3684 - accuracy: 0.9060 - val_loss: 1.3829 - val_accuracy: 0.4955\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.54406\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 79s 804ms/step - loss: 0.2749 - accuracy: 0.9329 - val_loss: 1.4325 - val_accuracy: 0.4866\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.54406\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 79s 812ms/step - loss: 0.1948 - accuracy: 0.9575 - val_loss: 1.5320 - val_accuracy: 0.4943\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.54406\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 80s 813ms/step - loss: 0.1374 - accuracy: 0.9741 - val_loss: 1.5453 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.54406\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 79s 807ms/step - loss: 0.1047 - accuracy: 0.9795 - val_loss: 1.6499 - val_accuracy: 0.4713\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54406\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 79s 804ms/step - loss: 0.0800 - accuracy: 0.9821 - val_loss: 1.7447 - val_accuracy: 0.4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [54:45<1:49:51, 1647.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.54406\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 87s 779ms/step - loss: 1.6308 - accuracy: 0.3697 - val_loss: 1.5398 - val_accuracy: 0.3929\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.39286, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 86s 786ms/step - loss: 1.5147 - accuracy: 0.3833 - val_loss: 1.4810 - val_accuracy: 0.4056\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.39286 to 0.40561, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 87s 789ms/step - loss: 1.4336 - accuracy: 0.4203 - val_loss: 1.4348 - val_accuracy: 0.4260\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.40561 to 0.42602, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 89s 805ms/step - loss: 1.3292 - accuracy: 0.4689 - val_loss: 1.3962 - val_accuracy: 0.4260\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.42602\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 89s 807ms/step - loss: 1.1857 - accuracy: 0.5476 - val_loss: 1.3643 - val_accuracy: 0.4311\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.42602 to 0.43112, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 87s 796ms/step - loss: 0.9620 - accuracy: 0.6692 - val_loss: 1.3913 - val_accuracy: 0.4439\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.43112 to 0.44388, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 88s 797ms/step - loss: 0.7092 - accuracy: 0.7761 - val_loss: 1.5157 - val_accuracy: 0.3827\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.44388\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 86s 782ms/step - loss: 0.4743 - accuracy: 0.8670 - val_loss: 1.6039 - val_accuracy: 0.4082\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.44388\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 85s 775ms/step - loss: 0.2977 - accuracy: 0.9230 - val_loss: 1.7758 - val_accuracy: 0.3903\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.44388\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 86s 784ms/step - loss: 0.1881 - accuracy: 0.9548 - val_loss: 1.9227 - val_accuracy: 0.4107\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.44388\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 83s 835ms/step - loss: 0.7263 - accuracy: 0.7737 - val_loss: 1.0401 - val_accuracy: 0.6169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.44388 to 0.61686, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 83s 851ms/step - loss: 0.5387 - accuracy: 0.8437 - val_loss: 1.0538 - val_accuracy: 0.6207\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.61686 to 0.62069, saving model to /kaggle/working/model_vocabulary.h5\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 0.3762 - accuracy: 0.8961 - val_loss: 1.0979 - val_accuracy: 0.6041\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62069\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 78s 798ms/step - loss: 0.2574 - accuracy: 0.9341 - val_loss: 1.1444 - val_accuracy: 0.6130\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62069\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 77s 787ms/step - loss: 0.1776 - accuracy: 0.9639 - val_loss: 1.2190 - val_accuracy: 0.5913\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62069\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 77s 788ms/step - loss: 0.1203 - accuracy: 0.9789 - val_loss: 1.2542 - val_accuracy: 0.5990\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62069\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 77s 784ms/step - loss: 0.0749 - accuracy: 0.9898 - val_loss: 1.3559 - val_accuracy: 0.5990\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.62069\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 78s 792ms/step - loss: 0.0484 - accuracy: 0.9939 - val_loss: 1.4280 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.62069\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 79s 809ms/step - loss: 0.0342 - accuracy: 0.9958 - val_loss: 1.5215 - val_accuracy: 0.5939\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.62069\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 79s 803ms/step - loss: 0.0238 - accuracy: 0.9981 - val_loss: 1.5598 - val_accuracy: 0.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [1:22:27<1:22:42, 1654.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62069\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 88s 795ms/step - loss: 1.7200 - accuracy: 0.2791 - val_loss: 1.6546 - val_accuracy: 0.2883\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28827, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 87s 791ms/step - loss: 1.6420 - accuracy: 0.3137 - val_loss: 1.6012 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.28827 to 0.31122, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 87s 787ms/step - loss: 1.5560 - accuracy: 0.3714 - val_loss: 1.5613 - val_accuracy: 0.3240\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.31122 to 0.32398, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 86s 782ms/step - loss: 1.4469 - accuracy: 0.4061 - val_loss: 1.5138 - val_accuracy: 0.3393\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.32398 to 0.33929, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 85s 775ms/step - loss: 1.2749 - accuracy: 0.5169 - val_loss: 1.4945 - val_accuracy: 0.3520\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.33929 to 0.35204, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 86s 780ms/step - loss: 1.0581 - accuracy: 0.6363 - val_loss: 1.5222 - val_accuracy: 0.3597\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.35204 to 0.35969, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 86s 778ms/step - loss: 0.8134 - accuracy: 0.7445 - val_loss: 1.5865 - val_accuracy: 0.3444\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.35969\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 86s 784ms/step - loss: 0.5443 - accuracy: 0.8585 - val_loss: 1.7530 - val_accuracy: 0.3469\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.35969\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 88s 801ms/step - loss: 0.3399 - accuracy: 0.9324 - val_loss: 1.8619 - val_accuracy: 0.3240\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.35969\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 88s 803ms/step - loss: 0.1935 - accuracy: 0.9693 - val_loss: 2.0136 - val_accuracy: 0.3163\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.35969\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 80s 812ms/step - loss: 0.8110 - accuracy: 0.7551 - val_loss: 1.0897 - val_accuracy: 0.6066\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.35969 to 0.60664, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 79s 802ms/step - loss: 0.6033 - accuracy: 0.8398 - val_loss: 1.1018 - val_accuracy: 0.6130\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.60664 to 0.61303, saving model to /kaggle/working/model_phraseology.h5\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 78s 800ms/step - loss: 0.4131 - accuracy: 0.9086 - val_loss: 1.1328 - val_accuracy: 0.6054\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61303\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 79s 805ms/step - loss: 0.2756 - accuracy: 0.9495 - val_loss: 1.2319 - val_accuracy: 0.5798\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61303\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 78s 796ms/step - loss: 0.1769 - accuracy: 0.9706 - val_loss: 1.2526 - val_accuracy: 0.5913\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61303\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 80s 815ms/step - loss: 0.1138 - accuracy: 0.9818 - val_loss: 1.3277 - val_accuracy: 0.5747\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.61303\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 0.0798 - accuracy: 0.9869 - val_loss: 1.3967 - val_accuracy: 0.5658\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.61303\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 0.0576 - accuracy: 0.9914 - val_loss: 1.4751 - val_accuracy: 0.5645\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.61303\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 0.0446 - accuracy: 0.9923 - val_loss: 1.5088 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.61303\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 81s 828ms/step - loss: 0.0333 - accuracy: 0.9942 - val_loss: 1.5753 - val_accuracy: 0.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [1:50:12<55:17, 1658.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.61303\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 89s 805ms/step - loss: 1.8105 - accuracy: 0.2393 - val_loss: 1.6900 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.25000, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 89s 813ms/step - loss: 1.7089 - accuracy: 0.2913 - val_loss: 1.6525 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.25000 to 0.28571, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 91s 824ms/step - loss: 1.6357 - accuracy: 0.3424 - val_loss: 1.6244 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.28571\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 90s 818ms/step - loss: 1.5270 - accuracy: 0.4186 - val_loss: 1.5791 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.28571 to 0.30102, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 90s 823ms/step - loss: 1.3883 - accuracy: 0.4882 - val_loss: 1.5882 - val_accuracy: 0.2934\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.30102\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 89s 811ms/step - loss: 1.1790 - accuracy: 0.5916 - val_loss: 1.5999 - val_accuracy: 0.3010\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.30102\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 90s 815ms/step - loss: 0.9100 - accuracy: 0.7056 - val_loss: 1.6505 - val_accuracy: 0.3367\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.30102 to 0.33673, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 89s 808ms/step - loss: 0.6613 - accuracy: 0.7954 - val_loss: 1.7371 - val_accuracy: 0.3214\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.33673\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 91s 830ms/step - loss: 0.4533 - accuracy: 0.8804 - val_loss: 1.8919 - val_accuracy: 0.3189\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.33673\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 90s 817ms/step - loss: 0.3173 - accuracy: 0.9190 - val_loss: 2.1055 - val_accuracy: 0.2806\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.33673\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 83s 844ms/step - loss: 0.6488 - accuracy: 0.8107 - val_loss: 1.1536 - val_accuracy: 0.5811\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.33673 to 0.58110, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 81s 830ms/step - loss: 0.4796 - accuracy: 0.8699 - val_loss: 1.1614 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.58110 to 0.58748, saving model to /kaggle/working/model_grammar.h5\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 82s 842ms/step - loss: 0.3552 - accuracy: 0.9105 - val_loss: 1.1938 - val_accuracy: 0.5798\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.58748\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 82s 839ms/step - loss: 0.2674 - accuracy: 0.9364 - val_loss: 1.2758 - val_accuracy: 0.5683\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.58748\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 83s 843ms/step - loss: 0.1880 - accuracy: 0.9613 - val_loss: 1.3505 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.58748\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 83s 850ms/step - loss: 0.1392 - accuracy: 0.9715 - val_loss: 1.5114 - val_accuracy: 0.5377\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.58748\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 82s 840ms/step - loss: 0.0955 - accuracy: 0.9856 - val_loss: 1.5339 - val_accuracy: 0.5415\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.58748\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 81s 827ms/step - loss: 0.0684 - accuracy: 0.9901 - val_loss: 1.6126 - val_accuracy: 0.5364\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.58748\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 80s 821ms/step - loss: 0.0464 - accuracy: 0.9939 - val_loss: 1.7695 - val_accuracy: 0.5147\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.58748\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 83s 843ms/step - loss: 0.0397 - accuracy: 0.9952 - val_loss: 1.8194 - val_accuracy: 0.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [2:18:54<28:01, 1681.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.58748\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 93s 835ms/step - loss: 1.7562 - accuracy: 0.2810 - val_loss: 1.6853 - val_accuracy: 0.2551\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.25510, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 90s 823ms/step - loss: 1.6926 - accuracy: 0.2967 - val_loss: 1.6684 - val_accuracy: 0.2959\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.25510 to 0.29592, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 90s 816ms/step - loss: 1.6537 - accuracy: 0.3160 - val_loss: 1.6552 - val_accuracy: 0.2832\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.29592\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 90s 819ms/step - loss: 1.5669 - accuracy: 0.3660 - val_loss: 1.6413 - val_accuracy: 0.3138\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.29592 to 0.31378, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 91s 826ms/step - loss: 1.4563 - accuracy: 0.4305 - val_loss: 1.6245 - val_accuracy: 0.3036\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.31378\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 90s 819ms/step - loss: 1.2761 - accuracy: 0.5439 - val_loss: 1.5589 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.31378 to 0.32653, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 88s 799ms/step - loss: 1.0339 - accuracy: 0.6729 - val_loss: 1.5832 - val_accuracy: 0.3240\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.32653\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 88s 801ms/step - loss: 0.7673 - accuracy: 0.7752 - val_loss: 1.6731 - val_accuracy: 0.3189\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.32653\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 89s 804ms/step - loss: 0.5059 - accuracy: 0.8770 - val_loss: 1.7829 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.32653\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 89s 806ms/step - loss: 0.3281 - accuracy: 0.9327 - val_loss: 1.9154 - val_accuracy: 0.3112\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.32653\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 81s 820ms/step - loss: 1.0465 - accuracy: 0.6621 - val_loss: 1.2487 - val_accuracy: 0.5734\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.32653 to 0.57344, saving model to /kaggle/working/model_conventions.h5\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 80s 814ms/step - loss: 0.8483 - accuracy: 0.7596 - val_loss: 1.2302 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57344\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 80s 814ms/step - loss: 0.6598 - accuracy: 0.8248 - val_loss: 1.2504 - val_accuracy: 0.5466\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57344\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 80s 815ms/step - loss: 0.4739 - accuracy: 0.8939 - val_loss: 1.2399 - val_accuracy: 0.5722\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57344\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 81s 824ms/step - loss: 0.3329 - accuracy: 0.9309 - val_loss: 1.3064 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57344\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 81s 828ms/step - loss: 0.2246 - accuracy: 0.9584 - val_loss: 1.3082 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57344\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 0.1547 - accuracy: 0.9754 - val_loss: 1.3569 - val_accuracy: 0.5492\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57344\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 0.1128 - accuracy: 0.9821 - val_loss: 1.4274 - val_accuracy: 0.5492\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57344\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 0.0838 - accuracy: 0.9859 - val_loss: 1.4744 - val_accuracy: 0.5364\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57344\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 82s 834ms/step - loss: 0.0624 - accuracy: 0.9879 - val_loss: 1.4990 - val_accuracy: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [2:47:18<00:00, 1673.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.57344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(target_col):\n",
    "    y_train = to_categorical(df_train[col]*2-2, num_classes)\n",
    "    model_save = WORK/f'model_{col}.h5'\n",
    "    checkpoint = ModelCheckpoint(model_save,\n",
    "                                 monitor = 'val_accuracy',\n",
    "                                 save_best_only = True,\n",
    "                                 verbose = 1)\n",
    "    model = model_init(max_len, max_words)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        validation_split = 0.1,\n",
    "                        callbacks = [checkpoint],\n",
    "                        verbose = 1)\n",
    "    model.load_weights(model_save)\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    history_2 = model.fit(x_train, y_train,\n",
    "                          batch_size = batch_size,\n",
    "                          epochs = epochs,\n",
    "                          validation_split = 0.2,\n",
    "                          callbacks = [checkpoint],\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e9aa50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T00:29:54.823579Z",
     "iopub.status.busy": "2022-10-03T00:29:54.823221Z",
     "iopub.status.idle": "2022-10-03T00:29:54.847916Z",
     "shell.execute_reply": "2022-10-03T00:29:54.846613Z"
    },
    "papermill": {
     "duration": 0.745911,
     "end_time": "2022-10-03T00:29:54.849864",
     "exception": false,
     "start_time": "2022-10-03T00:29:54.103953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(DATA/'test.csv')\n",
    "sample = pd.read_csv(DATA/'sample_submission.csv')\n",
    "sample.text_id = test.text_id\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8756d0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T00:29:56.298988Z",
     "iopub.status.busy": "2022-10-03T00:29:56.298657Z",
     "iopub.status.idle": "2022-10-03T00:29:56.309159Z",
     "shell.execute_reply": "2022-10-03T00:29:56.308306Z"
    },
    "papermill": {
     "duration": 0.769394,
     "end_time": "2022-10-03T00:29:56.310998",
     "exception": false,
     "start_time": "2022-10-03T00:29:55.541604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 7589.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test.full_text = preprocess(test.full_text)\n",
    "x_test = token.texts_to_sequences(test.full_text)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c3133e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T00:29:57.742134Z",
     "iopub.status.busy": "2022-10-03T00:29:57.741063Z",
     "iopub.status.idle": "2022-10-03T00:29:58.449021Z",
     "shell.execute_reply": "2022-10-03T00:29:58.447614Z"
    },
    "papermill": {
     "duration": 1.471899,
     "end_time": "2022-10-03T00:29:58.450982",
     "exception": false,
     "start_time": "2022-10-03T00:29:56.979083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 160ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:00<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def label_transform(pred):\n",
    "    labels = []\n",
    "    for i in range(len(pred)):\n",
    "        max_p = max(pred[i])\n",
    "        for j in range(num_classes):\n",
    "            if max_p == pred[i][j]:\n",
    "                ind = (j + 2) / 2\n",
    "                break\n",
    "        labels.append(ind)\n",
    "    return labels\n",
    "\n",
    "for col in tqdm(target_col):\n",
    "    model.load_weights(model_save)\n",
    "    test_pred = model.predict(x_test,\n",
    "                              batch_size = batch_size,\n",
    "                              verbose = 1)\n",
    "    sample[col] = label_transform(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae916ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T00:29:59.822404Z",
     "iopub.status.busy": "2022-10-03T00:29:59.822034Z",
     "iopub.status.idle": "2022-10-03T00:29:59.831051Z",
     "shell.execute_reply": "2022-10-03T00:29:59.829952Z"
    },
    "papermill": {
     "duration": 0.67632,
     "end_time": "2022-10-03T00:29:59.833070",
     "exception": false,
     "start_time": "2022-10-03T00:29:59.156750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10063.24542,
   "end_time": "2022-10-03T00:30:04.081956",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-02T21:42:20.836536",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
